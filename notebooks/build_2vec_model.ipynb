{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "\n",
    "# Packages\n",
    "import pandas\n",
    "\n",
    "# LexNLP imports\n",
    "from lexnlp.nlp.en.segments.sentences import get_sentence_list\n",
    "from lexnlp.nlp.en.tokens import get_token_list, get_stem_list\n",
    "\n",
    "# Imports\n",
    "import gensim.models.word2vec\n",
    "import gensim.models.doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup constants\n",
    "HTML_INPUT_PATH = \"../data/text/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Court-years detected: 292\n"
     ]
    }
   ],
   "source": [
    "# Build list of paths to review\n",
    "court_path_list = []\n",
    "for country in os.listdir(HTML_INPUT_PATH):\n",
    "    for level_a in os.listdir(os.path.join(HTML_INPUT_PATH, country, \"cases\")):\n",
    "        for level_b in os.listdir(os.path.join(HTML_INPUT_PATH, country, \"cases\", level_a)):\n",
    "            if level_b.isdigit():\n",
    "                court_path_list.append({\"court_name\": level_a,\n",
    "                                        \"court_division\": None,\n",
    "                                        \"country\": country,\n",
    "                                        \"year\": int(level_b),\n",
    "                                        \"path\": os.path.join(HTML_INPUT_PATH, country, \"cases\", level_a, level_b)})\n",
    "                continue\n",
    "\n",
    "            for level_c in os.listdir(os.path.join(HTML_INPUT_PATH, country, \"cases\", level_a, level_b)):\n",
    "                court_path_list.append({\"court_name\": level_a,\n",
    "                                        \"court_division\": level_b,\n",
    "                                        \"country\": country,\n",
    "                                        \"year\": int(level_c),\n",
    "                                        \"path\": os.path.join(HTML_INPUT_PATH, country, \"cases\", level_a, level_b, level_c)})\n",
    "\n",
    "print(\"Court-years detected: {0}\".format(len(court_path_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('EWHC', 'Admlty', 2015, 6)\n",
      "('EWHC', 'Admlty', 2003, 4)\n",
      "('EWHC', 'Admlty', 2017, 1)\n",
      "('EWHC', 'Admlty', 2006, 1)\n",
      "('EWHC', 'Admlty', 2002, 7)\n",
      "('EWHC', 'Admlty', 2004, 4)\n",
      "('EWHC', 'Admlty', 2014, 4)\n",
      "('EWHC', 'Admlty', 2001, 7)\n",
      "('EWHC', 'Admlty', 2005, 3)\n",
      "('EWHC', 'Admlty', 2009, 8)\n",
      "('EWHC', 'Admlty', 1999, 1)\n",
      "('EWHC', 'Admlty', 2016, 1)\n",
      "('EWHC', 'Admlty', 2011, 5)\n",
      "('EWHC', 'Admlty', 2013, 3)\n",
      "('EWHC', 'Admlty', 2012, 3)\n",
      "('EWHC', 'Admlty', 2008, 6)\n",
      "('EWHC', 'Admlty', 2000, 2)\n",
      "('EWHC', 'Admlty', 2018, 2)\n",
      "('EWHC', 'Admlty', 2007, 2)\n",
      "('EWHC', 'Admlty', 2010, 3)\n",
      "('EWHC', 'Admin', 2015, 714)\n",
      "('EWHC', 'Admin', 2003, 626)\n"
     ]
    }
   ],
   "source": [
    "# setup key storage\n",
    "sentences = []\n",
    "documents = []\n",
    "\n",
    "# Iterate through court-year paths\n",
    "for court_path in court_path_list:\n",
    "    # Get file list\n",
    "    court_year_file_list = os.listdir(court_path[\"path\"])\n",
    "    print((court_path[\"court_name\"],\n",
    "           court_path[\"court_division\"],\n",
    "           court_path[\"year\"],\n",
    "           len(court_year_file_list)          \n",
    "          ))\n",
    "    \n",
    "    for case_file_name in court_year_file_list:\n",
    "        case_file_path = os.path.join(court_path[\"path\"], case_file_name)\n",
    "        with open(case_file_path, \"r\") as input_file:\n",
    "            text_content = input_file.read()\n",
    "        \n",
    "        doc_stems = []\n",
    "        for sentence in get_sentence_list(text_content):\n",
    "            sentence_stems = [s for s in get_stem_list(sentence, stopword=True, lowercase=True) if s.isalpha()]\n",
    "            doc_stems.extend(sentence_stems)\n",
    "            sentences.append(sentence_stems)\n",
    "        documents.append(gensim.models.doc2vec.TaggedDocument(doc_stems, [\"{0}\".format(case_file_path)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec models\n",
    "min_count = 10\n",
    "w2v_size_list = [100, 200]\n",
    "w2v_window_list = [5, 10, 20]\n",
    "for size in w2v_size_list:\n",
    "    for window in w2v_window_list:\n",
    "        w2v_model_cbow = gensim.models.word2vec.Word2Vec(sentences, size=size, window=window, min_count=min_count, workers=1)\n",
    "        w2v_model_cbow.save(\"../data/models/w2v_cbow_all_size{0}_window{1}\".format(size, window))\n",
    "\n",
    "# doc2vec models\n",
    "min_count = 10\n",
    "d2v_size_list = [100, 200]\n",
    "d2v_window_list = [5, 10, 20]\n",
    "for size in d2v_size_list:\n",
    "    for window in d2v_window_list:\n",
    "        d2v_model = gensim.models.doc2vec.Doc2Vec(documents, vector_size=size, window=window, min_count=min_count, workers=1)\n",
    "        d2v_model.save(\"../data/models/d2v_all_size{0}_window{1}\".format(size, window))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
